{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Linear\n",
    "from torch.optim import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexLinearLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(ComplexLinearLayer, self).__init__()\n",
    "        self.W_r = Linear(in_features, out_features,bias=True)\n",
    "        self.W_i = Linear(in_features, out_features,bias=True)\n",
    "        \n",
    "    def forward(self,in_r, in_i):\n",
    "        Real_OUT = self.W_r(in_r) - self.W_i(in_i)\n",
    "        Imag_OUT = self.W_r(in_i) + self.W_i(in_r)\n",
    "        return Real_OUT, Imag_OUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_sign_activation(in_r, in_i):\n",
    "    return torch.sign(in_r), torch.sign(in_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexNetworkPaper(nn.Module):\n",
    "    def __init__(self,in_features,hidden_features):\n",
    "        super(ComplexNetworkPaper,self).__init__()\n",
    "        self.input_linear_Layer = ComplexLinearLayer(in_features,hidden_features)\n",
    "        \n",
    "    def forward(self,in_r,in_i):\n",
    "        hidden_r,hidden_i = self.input_linear_Layer(in_r,in_i)\n",
    "        output_r,output_i = complex_sign_activation(hidden_r,hidden_i)\n",
    "        \n",
    "        return output_r,output_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss_with_tanh(input_r, input_i, target_r, target_i, H_r,H_i, bias_r,bias_i, lam=0.01):\n",
    "    '''\n",
    "    bias_r: z for the real part\n",
    "    bias_i: z for the imaginary part\n",
    "    H_r: weight matrix( the channel matrix) (real)\n",
    "    H_i: weight matrix( the channel matrix) (imaginary)\n",
    "    input_r: real part of the input\n",
    "    input_i: imaginary part of the input\n",
    "    target_r: real part of the target\n",
    "    target_i: imaginary part of the target\n",
    "    '''\n",
    "    # Compute H * x_n + z for r and i parts\n",
    "    temp_r = torch.matmul(input_r, H_r.t()) + bias_r\n",
    "    temp_i = torch.matmul(input_i, H_i.t()) + bias_i\n",
    "    \n",
    "    # (tanh(Hx_n + z))\n",
    "    tanh_r = torch.tanh(temp_r)\n",
    "    tanh_i = torch.tanh(temp_i)\n",
    "    \n",
    "    # first_term = 1/N sum [tanh(H * x_n + z)(REAL) + tanh(H * x_n + z)(IMAG)]\n",
    "    first_term = torch.mean(torch.norm(target_r - tanh_r, dim=1)**2 + torch.norm(target_i - tanh_i, dim=1)**2)\n",
    "    \n",
    "\n",
    "    regul_term = lam * (torch.norm(H_r, p=2)+torch.norm(H_i, p=2))\n",
    "    loss = first_term + regul_term\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_r = torch.randn(10, 5)  # 10 is the batch size, so the forwad function will handle these 10 samples at once, and so the same weights are being used for all of these 10 samples \n",
    "in_i = torch.randn(10, 5)\n",
    "target_r = torch.randn(10, 5)  \n",
    "target_i = torch.randn(10, 5)\n",
    "model = ComplexNetworkPaper(in_features=in_r.shape[1], hidden_features=target_r.shape[1])\n",
    "optimizer = SGD(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    \n",
    "    # Forward pass\n",
    "    output_r, output_i = model(in_r, in_i)\n",
    "    \n",
    "    # LOss\n",
    "    loss = custom_loss_with_tanh(input_r=in_r, input_i=in_i, target_r=target_r, target_i=target_i, H_r=model.input_linear_Layer.W_r.weight,H_i = model.input_linear_Layer.W_i.weight, bias_r=model.input_linear_Layer.W_r.bias,bias_i=model.input_linear_Layer.W_i.bias)\n",
    "    \n",
    "    # Backpropagation and optimization\n",
    "    optimizer.zero_grad()  # reset the gradients\n",
    "    loss.backward()  # Backpropgation to calculation the new gradients\n",
    "    optimizer.step()  # Update the weights in the direction of these new gradients\n",
    "\n",
    "    print(f'Epoch {epoch}, Loss: {loss.item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
